{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 style=\"text-align:center\">Deep Learning  Lab Session </h1>\n",
    "<h1 style=\"text-align:center\">First Lab Session - 3 Hours </h1>\n",
    "<h1 style=\"text-align:center\">Artificial Neural Networks for Handwritten Digits Recognition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Student 1:</b> Benedetto Luca  \n",
    "<b> Student 2:</b> Ibarrondo Alberto\n",
    " \n",
    " \n",
    "The aim of this session is to practice with Artificial Neural Networks. Answers and experiments should be made by groups of one or two students. Each group should fill and run appropriate notebook cells. \n",
    "\n",
    "To generate your final report, use print as PDF (Ctrl+P). Do not forget to run all your cells before generating your final report and do not forget to include the names of all participants in the group. The lab session should be completed by April 7th 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "In this session, your will implement, train and test a Neural Network\n",
    "for the Handwritten Digits Recognition problem <a href=\"http://yann.lecun.com/exdb/mnist/\"> [1] </a> with  different settings of hyper parameters. You will use the MNIST dataset which was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). Images of digits were taken from a variety of scanned documents, normalized in size and centered. \n",
    "\n",
    "\n",
    "<img src=\"Nimages/mnist.png\",width=\"350\" height=\"500\" align=\"center\">\n",
    "<center><span>Figure 1: MNIST digits examples</span></center>\n",
    "\n",
    "\n",
    "This assignment includes a written part of programms to help you understand how to build and train\n",
    "your neural net and then to test your code and get restults. \n",
    "\n",
    "1. <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> \n",
    "2. <a href=\"transfer_functions.py\"> transfer_functions.py </a> \n",
    "3.  <a href=\"utils.py \"> utils.py </a> \n",
    "\n",
    "\n",
    "Functions defined inside the python files mentionned above can be imported  using the python command : \n",
    "from filename import *\n",
    "\n",
    "You will use the following libraries:\n",
    "\n",
    "1. <a href=\"http://cs231n.github.io/python-numpy-tutorial/\"> numpy </a>: for creating arrays and using methods to manipulate arrays.\n",
    "\n",
    "2. <a href=\"http://matplotlib.org/\"> matplotlib  </a>: for making plots\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 :  My First Neural Network\n",
    "\n",
    "<b>Part 1</b>: Before designing and writing your code, you will first work on a neural network by hand. \n",
    "Consider the above Neural network with two inputs $X=(x1,x2)$, one hidden layers and a single output unit $(y)$.\n",
    "The initial weights are set to random values. Neurons 6 and 7 represent the bias. Bias values are equal to 1.  \n",
    "Training sample, X = (0.8, 0.2), whose class label is Y=0.4.\n",
    "\n",
    "Assume that the neurons have a Sigmoid activation function  $f(x)=\\frac{1}{(1+e^{-x})}$ and the learning rate $\\mu$=1\n",
    "\n",
    "\n",
    "<img src=\"Nimages/NN.png\", width=\"700\" height=\"900\"> \n",
    "<center><span>Figure 2: Neural network </span></center>\n",
    "\n",
    "\n",
    "<b>Question 1.1.1</b>: Compute the new values of weights $w_{i,j}$ after a forward pass and a backward pass.\n",
    "$w_{i,j}$ is the weight of the connexion between neuron $i$ and neuron $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import Resources.NNet as nn\n",
    "import Resources.transfer_functions as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3,) doesn't match the broadcast shape (1,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-37741d8a7f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdEdu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdEdu2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdsigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mw2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdEdu2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdEdu1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (3,) doesn't match the broadcast shape (1,3)"
     ]
    }
   ],
   "source": [
    "# Calculating manually all the values (printing has been supressed)\n",
    "# Initial values\n",
    "x = np.array([0.8, 0.2, 1])\n",
    "w1 = np.array([[0.3, -0.5], [0.8, 0.2], [0.2, -0.4]])\n",
    "w2 = np.array([-0.6, 0.4, 0.5])\n",
    "y = np.array(0.4)\n",
    "u = np.array(1)\n",
    "\n",
    "#Feedforward computation\n",
    "u1 = np.append(np.dot(x, w1), 1.0)\n",
    "o1 = tf.sigmoid(u1)\n",
    "\n",
    "u2 = np.dot(o1, w2)\n",
    "o2 = tf.sigmoid(u2)\n",
    "\n",
    "\n",
    "#Backward computation\n",
    "E = (1.0/2.0)*((y-o2)**2.0)\n",
    "\n",
    "dEdu2 = (y-o2)*tf.dsigmoid(o2)\n",
    "dEdu1 = w2.dot(dEdu2)*tf.dsigmoid(o1)\n",
    "\n",
    "w2 += u*np.outer(dEdu2,o1)\n",
    "w1 += u*np.outer(x,dEdu1[:-1])\n",
    "\n",
    "print('dEdu2: ', dEdu2)\n",
    "print('dEdu1: ', dEdu1)\n",
    "print('x: ', x)\n",
    "print('w2 : ', w2)\n",
    "print('w1: ', w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here :\n",
    "\n",
    "$w_{1,3}=  0.30345983 $ \n",
    "\n",
    "$w_{1,4}=  -0.50218887 $\n",
    "\n",
    "$w_{2,3}= 0.80086496 $\n",
    "\n",
    "$w_{2,4}= 0.19945278 $\n",
    "\n",
    "$w_{6,3}= 0.20432479 $\n",
    "\n",
    "$w_{6,4}= -0.40273608 $\n",
    "\n",
    "$w_{3,5}= -0.62034179 $\n",
    "\n",
    "$w_{4,5}= 0.38996086 $\n",
    "\n",
    "$w_{7,5}= 0.47696756 $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Neural Network Implementation\n",
    "\n",
    "Please read all source files carefully and understand the data structures and all functions.\n",
    "You are to complete the missing code. \n",
    "First you should define the neural network (using the NeuralNetwork class, see in the <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> file) and reinitialise weights. \n",
    "Then you will to complete the Feed Forward and the Back-propagation functions. \n",
    "\n",
    "<b>Question 1.2.1</b>: Define the neural network corresponding to the one in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create the network\n",
    "my_nnet = nn.NNet(2,2,1,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3 -0.5]\n",
      " [ 0.8  0.2]\n",
      " [ 0.2 -0.4]]\n",
      "[[-0.6]\n",
      " [ 0.4]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#Data preparation \n",
    "X=[0.8,0.2]\n",
    "Y=[0.4]\n",
    "data=[]\n",
    "data.append(X)\n",
    "data.append(Y)\n",
    "\n",
    "#initialize weights\n",
    "wi=np.array([[0.3,-0.5],[0.8,0.2],[0.2,-0.4]])\n",
    "wo=np.array([[-0.6],[0.4],[0.5]])\n",
    "my_nnet.init_w(wi,wo)\n",
    "print(my_nnet.Wi_h)\n",
    "print(my_nnet.Wh_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.2</b>: Implement the Feed Forward function (feedForward(X) in the NeuralNetwork.py file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check your network outputs the expected value (the one you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output activation =0.526\n"
     ]
    }
   ],
   "source": [
    "# test my  Feed Forward function \n",
    "Output_activation=my_nnet.feedForward(X)\n",
    "print(\"output activation =%.3f\" %(Output_activation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.3</b>: Implement the Back-propagation Algorithm (backPropagate(Y) in the NeuralNetwork.py file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def myBackPropagate(nn, targets):\n",
    "    # Implement it in the NeuralNetwork.py file and when finalised copy and paste your FeedForward function here\n",
    "    nn.dEdU2 = (nn.a_out-targets)*tf.dsigmoid(nn.a_out)\n",
    "    # calculate error terms for hidden\n",
    "    nn.dEdU1 = np.multiply(np.dot(nn.Wh_o,nn.dEdU2), tf.dsigmoid(nn.a_hidden))\n",
    "    # update output weights\n",
    "    nn.Wh_o = nn.Wh_o - nn.learning_rate*np.outer(nn.a_hidden,nn.dEdU2)\n",
    "    # update input weights\n",
    "    nn.Wi_h = nn.Wi_h - nn.learning_rate*np.outer(nn.a_input,nn.dEdU1[:-1])\n",
    "    # calculate error\n",
    "    E = (1.0/2.0)*((targets-nn.a_out)**2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check the gradient values and weight updates are correct (similar to the ones you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi_new= [[ 0.30345983 -0.50218887]\n",
      " [ 0.80086496  0.19945278]\n",
      " [ 0.20432479 -0.40273608]]\n",
      "wo_new= [[-0.62034179]\n",
      " [ 0.38996086]\n",
      " [ 0.47696756]]\n"
     ]
    }
   ],
   "source": [
    "#test Back-propagation function\n",
    "my_nnet.init_w(wi,wo)\n",
    "Output_activation=my_nnet.feedForward(X)\n",
    "my_nnet.backPropagate(Y)\n",
    "print('wi_new=', my_nnet.Wi_h)\n",
    "print('wo_new=', my_nnet.Wh_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.62034179  0.38996086  0.47696756]]\n",
      "[[-0.62034179]\n",
      " [ 0.38996086]\n",
      " [ 0.47696756]]\n",
      "[[ 0.30345983 -0.50218887]\n",
      " [ 0.80086496  0.19945278]\n",
      " [ 0.20432479 -0.40273608]]\n",
      "[[ 0.30345983 -0.50218887]\n",
      " [ 0.80086496  0.19945278]\n",
      " [ 0.20432479 -0.40273608]]\n"
     ]
    }
   ],
   "source": [
    "#Print weights after backpropagation and comparing\n",
    "print(w2)\n",
    "print(my_nnet.Wh_o)\n",
    "print(w1)\n",
    "print(my_nnet.Wi_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Your Feed Forward and Back-Propagation implementations are working, Great!! Let's tackle a real world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2 : The MNIST Challenge! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Data Preparation</b>\n",
    "\n",
    "The MNIST dataset consists of handwritten digit images it contains 60,000 examples for the training set and 10,000 examples for testing. In this Lab Session, the official training set of 60,000 is divided into an actual training set of 50,000 examples, 10,000 validation examples and 10,000 examples for test. All digit images have been size-normalized and centered in a fixed size image of 28 x 28 pixels. The images are stored in byte form you will use the NumPy python library to read the data files into NumPy arrays that we will use to train the ANN.\n",
    "\n",
    "The MNIST dataset is available in the Data folder.\n",
    "To get the training, testing and validation data, run the the load_data() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Resources.utils import *\n",
    "import gzip\n",
    "import _pickle as cPickle\n",
    "f = gzip.open('Resources/mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "#training_data, validation_data, test_data=load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>MNIST Dataset Digits Visualisation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ROW = 2\n",
    "COLUMN = 4\n",
    "for i in range(ROW * COLUMN):\n",
    "    # train[i][0] is i-th image data with size 28x28\n",
    "    image = training_data[i][0].reshape(28, 28)   \n",
    "    plt.subplot(ROW, COLUMN, i+1)          \n",
    "    plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n",
    "plt.axis('off')  # do not show axis value\n",
    "plt.tight_layout()   # automatic padding between subplots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 1</b>: Creating the Neural Networks\n",
    "\n",
    "The input layer of the neural network contains neurons encoding the values of the input pixels. The training data for the network will consist of many 28 by 28 pixel images of scanned handwritten digits, and so the input layer contains 784=28Ã—28 neurons. The second layer of the network is a hidden layer, we set the neuron number in the hidden layer to 30. The output layer contains 10 neurons. \n",
    "\n",
    "<b>Question 2.1.1</b>: Create the network described above using the NeuralNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "my_mnist_net = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.2</b>: Add the information about the performance of the neural network on the test set at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_accuracy=my_mnist_net.predict(test_data)/100\n",
    "print('Test_Accuracy  %-2.2f' % test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.3</b>: Train the Neural Network and comment your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train your network \n",
    "my_mnist_net.train(training_data,validation_data)\n",
    "\n",
    "#save your model in Models/ using a distinguishing name for your model (architecture, learning rate, etc...)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Note your observations here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.4</b>: Guess digit, Implement and test a python function that predict the class of a digit (the folder images_test contains some examples of images of digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Change the neural network structure and parameters to optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.1</b>: Change the learning rate (0.001, 0.1, 1.0 , 10). Train the new neural nets with the original specifications (Part 2.1), for 50 iterations. \n",
    "Plot test accuracy vs iteration for each learning rate on the same graph. Report the maximum\n",
    "test accuracy achieved for each learning rate. Which one achieves the maximum test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation with a learning rate of 0.001 goes here \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation with a learning rate of 1.0 goes here \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation with a learning rate of 10 goes here \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer for Question 2.2.1 goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <b> Question 2.2.2 : </b> initialize all weights to 0.  Plot the training accuracy curve.\n",
    "Comment your results\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.3 : </b> Try with a different transfer function (such as tanh).\n",
    " File transfer_functions.py provides you the python implementation of the tanh function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<b> Question 2.2.4 : </b>  Add more neurons in the hidden layer (try with 100, 200, 300). Plot the curve representing the validation accuracy versus the number of neurons in the hidden layer.  (Choose and justify other hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.5 : </b> Add one additionnal hidden layers and train your network, discuss your results with different setting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
